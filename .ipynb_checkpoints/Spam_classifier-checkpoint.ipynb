{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This is the spam classifier made to which can be found in [http://spamassassin.apache.org/old/publiccorpus/]. This is the easy one found in there.__ There are other models who can do more than 98% precision/recall- they have custom made feature extraction classes. This has lesser precision/recall. And this is just for practice for me to use the scikit-library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T02:45:24.926560Z",
     "start_time": "2020-09-26T02:45:24.326541Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "# make the run consistent across all runs\n",
    "np.random.seed(42)\n",
    "import matplotlib as mlt\n",
    "import matplotlib.pyplot as plt\n",
    "#make the figures better understandable\n",
    "mlt.rc('xtick', labelsize=18)\n",
    "mlt.rc('ytick', labelsize=18)\n",
    "mlt.rc('axes', labelsize=15)\n",
    "\n",
    "#to ignore useless warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First  we have to fetch the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T02:45:28.916831Z",
     "start_time": "2020-09-26T02:45:28.876708Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import tarfile \n",
    "import urllib\n",
    "\n",
    "download_root = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
    "ham_url = download_root + '20030228_easy_ham.tar.bz2'\n",
    "spam_url = download_root + '20030228_spam.tar.bz2'\n",
    "spam_path = os.path.join('datasets', 'spam')\n",
    "\n",
    "#a function ot fetch the datasets\n",
    "\n",
    "def fetch_spam_data(spam_url, spam_path):\n",
    "    if not os.path.isdir(spam_path):os.makedirs(spam_path)\n",
    "    for filename, url in ((\"ham.tar.bz2\", ham_url), ('spam.tar.bz2', spam_url)):\n",
    "        path = os.path.join(spam_path, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        tar_bz2_file = tarfile.open(path)\n",
    "        tar_bz2_file.extractall(path=spam_path)\n",
    "        tar_bz2_file.close()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T02:45:36.776393Z",
     "start_time": "2020-09-26T02:45:30.856527Z"
    }
   },
   "outputs": [],
   "source": [
    "fetch_spam_data(spam_url, spam_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T02:45:37.636737Z",
     "start_time": "2020-09-26T02:45:37.591654Z"
    }
   },
   "outputs": [],
   "source": [
    "HAM_DIR = os.path.join(spam_path, \"easy_ham\")\n",
    "SPAM_DIR = os.path.join(spam_path, \"spam\")\n",
    "ham_filename = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
    "spam_filename = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T02:45:41.536634Z",
     "start_time": "2020-09-26T02:45:41.518830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ham_filename), len(spam_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T02:45:46.906483Z",
     "start_time": "2020-09-26T02:45:46.876425Z"
    }
   },
   "outputs": [],
   "source": [
    "#using the python email module to parse these emails\n",
    "import email\n",
    "import email.policy \n",
    "\n",
    "def load_email(is_spam, filename, spam_path=spam_path):\n",
    "    directory = 'spam' if is_spam else 'easy_ham'\n",
    "    with open(os.path.join(spam_path, directory, filename), 'rb') as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T02:46:05.336433Z",
     "start_time": "2020-09-26T02:45:48.756617Z"
    }
   },
   "outputs": [],
   "source": [
    "ham_emails = [load_email( is_spam=False, filename=name) for name in ham_filename]\n",
    "spam_emails = [load_email(is_spam=True, filename=name) for name in spam_filename]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The emails can be seen like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T02:17:33.038095Z",
     "start_time": "2020-09-26T02:17:33.020164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Date:        Wed, 21 Aug 2002 10:54:46 -0500\n",
      "    From:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n",
      "    Message-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
      "\n",
      "\n",
      "  | I can't reproduce this error.\n",
      "\n",
      "For me it is very repeatable... (like every time, without fail).\n",
      "\n",
      "This is the debug log of the pick happening ...\n",
      "\n",
      "18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\n",
      "18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\n",
      "18:19:04 Ftoc_PickMsgs {{1 hit}}\n",
      "18:19:04 Marking 1 hits\n",
      "18:19:04 tkerror: syntax error in expression \"int ...\n",
      "\n",
      "Note, if I run the pick command by hand ...\n",
      "\n",
      "delta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury\n",
      "1 hit\n",
      "\n",
      "That's where the \"1 hit\" comes from (obviously).  The version of nmh I'm\n",
      "using is ...\n",
      "\n",
      "delta$ pick -version\n",
      "pick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]\n",
      "\n",
      "And the relevant part of my .mh_profile ...\n",
      "\n",
      "delta$ mhparam pick\n",
      "-seq sel -list\n",
      "\n",
      "\n",
      "Since the pick command works, the sequence (actually, both of them, the\n",
      "one that's explicit on the command line, from the search popup, and the\n",
      "one that comes from .mh_profile) do get created.\n",
      "\n",
      "kre\n",
      "\n",
      "ps: this is still using the version of the code form a day ago, I haven't\n",
      "been able to reach the cvs repository today (local routing issue I think).\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________\n",
      "Exmh-workers mailing list\n",
      "Exmh-workers@redhat.com\n",
      "https://listman.redhat.com/mailman/listinfo/exmh-workers\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ham_emails[0].get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T02:17:33.657682Z",
     "start_time": "2020-09-26T02:17:33.043100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n",
      "<HTML><HEAD>\n",
      "<META content=\"text/html; charset=windows-1252\" http-equiv=Content-Type>\n",
      "<META content=\"MSHTML 5.00.2314.1000\" name=GENERATOR></HEAD>\n",
      "<BODY><!-- Inserted by Calypso -->\n",
      "<TABLE border=0 cellPadding=0 cellSpacing=2 id=_CalyPrintHeader_ rules=none \n",
      "style=\"COLOR: black; DISPLAY: none\" width=\"100%\">\n",
      "  <TBODY>\n",
      "  <TR>\n",
      "    <TD colSpan=3>\n",
      "      <HR color=black noShade SIZE=1>\n",
      "    </TD></TR></TD></TR>\n",
      "  <TR>\n",
      "    <TD colSpan=3>\n",
      "      <HR color=black noShade SIZE=1>\n",
      "    </TD></TR></TBODY></TABLE><!-- End Calypso --><!-- Inserted by Calypso --><FONT \n",
      "color=#000000 face=VERDANA,ARIAL,HELVETICA size=-2><BR></FONT></TD></TR></TABLE><!-- End Calypso --><FONT color=#ff0000 \n",
      "face=\"Copperplate Gothic Bold\" size=5 PTSIZE=\"10\">\n",
      "<CENTER>Save up to 70% on Life Insurance.</CENTER></FONT><FONT color=#ff0000 \n",
      "face=\"Copperplate Gothic Bold\" size=5 PTSIZE=\"10\">\n",
      "<CENTER>Why Spend More Than You Have To?\n",
      "<CENTER><FONT color=#ff0000 face=\"Copperplate Gothic Bold\" size=5 PTSIZE=\"10\">\n",
      "<CENTER>Life Quote Savings\n",
      "<CENTER>\n",
      "<P align=left></P>\n",
      "<P align=left></P></FONT></U></I></B><BR></FONT></U></B></U></I>\n",
      "<P></P>\n",
      "<CENTER>\n",
      "<TABLE border=0 borderColor=#111111 cellPadding=0 cellSpacing=0 width=650>\n",
      "  <TBODY></TBODY></TABLE>\n",
      "<TABLE border=0 borderColor=#111111 cellPadding=5 cellSpacing=0 width=650>\n",
      "  <TBODY>\n",
      "  <TR>\n",
      "    <TD colSpan=2 width=\"35%\"><B><FONT face=Verdana size=4>Ensuring your \n",
      "      family's financial security is very important. Life Quote Savings makes \n",
      "      buying life insurance simple and affordable. We Provide FREE Access to The \n",
      "      Very Best Companies and The Lowest Rates.</FONT></B></TD></TR>\n",
      "  <TR>\n",
      "    <TD align=middle vAlign=top width=\"18%\">\n",
      "      <TABLE borderColor=#111111 width=\"100%\">\n",
      "        <TBODY>\n",
      "        <TR>\n",
      "          <TD style=\"PADDING-LEFT: 5px; PADDING-RIGHT: 5px\" width=\"100%\"><FONT \n",
      "            face=Verdana size=4><B>Life Quote Savings</B> is FAST, EASY and \n",
      "            SAVES you money! Let us help you get started with the best values in \n",
      "            the country on new coverage. You can SAVE hundreds or even thousands \n",
      "            of dollars by requesting a FREE quote from Lifequote Savings. Our \n",
      "            service will take you less than 5 minutes to complete. Shop and \n",
      "            compare. SAVE up to 70% on all types of Life insurance! \n",
      "</FONT></TD></TR>\n",
      "        <TR><BR><BR>\n",
      "          <TD height=50 style=\"PADDING-LEFT: 5px; PADDING-RIGHT: 5px\" \n",
      "          width=\"100%\">\n",
      "            <P align=center><B><FONT face=Verdana size=5><A \n",
      "            href=\"http://website.e365.cc/savequote/\">Click Here For Your \n",
      "            Free Quote!</A></FONT></B></P></TD>\n",
      "          <P><FONT face=Verdana size=4><STRONG>\n",
      "          <CENTER>Protecting your family is the best investment you'll ever \n",
      "          make!<BR></B></TD></TR>\n",
      "        <TR><BR><BR></STRONG></FONT></TD></TR></TD></TR>\n",
      "        <TR></TR></TBODY></TABLE>\n",
      "      <P align=left><FONT face=\"Arial, Helvetica, sans-serif\" size=2></FONT></P>\n",
      "      <P></P>\n",
      "      <CENTER><BR><BR><BR>\n",
      "      <P></P>\n",
      "      <P align=left><BR></B><BR><BR><BR><BR></P>\n",
      "      <P align=center><BR></P>\n",
      "      <P align=left><BR></B><BR><BR></FONT>If you are in receipt of this email \n",
      "      in error and/or wish to be removed from our list, <A \n",
      "      href=\"mailto:coins@btamail.net.cn\">PLEASE CLICK HERE</A> AND TYPE REMOVE. If you \n",
      "      reside in any state which prohibits e-mail solicitations for insurance, \n",
      "      please disregard this \n",
      "      email.<BR></FONT><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR></FONT></P></CENTER></CENTER></TR></TBODY></TABLE></CENTER></CENTER></CENTER></CENTER></CENTER></BODY></HTML>\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(spam_emails[0].get_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the type of emails that are there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T02:46:14.111720Z",
     "start_time": "2020-09-26T02:46:14.097955Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def get_email_str(email):\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        return f\"multipart({ ', '.join([get_email_str(sub_email) for sub_email in payload])})\"\n",
    "    else:\n",
    "        return email.get_content_type()\n",
    "def str_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_str(email)\n",
    "        structures[structure] += 1\n",
    "    return structures\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T02:46:16.711576Z",
     "start_time": "2020-09-26T02:46:16.076631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 2408),\n",
       " ('multipart(text/plain, application/pgp-signature)', 66),\n",
       " ('multipart(text/plain, text/html)', 8),\n",
       " ('multipart(text/plain, text/plain)', 4),\n",
       " ('multipart(text/plain)', 3),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, text/enriched)', 1),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
       " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, video/mng)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
       "  1),\n",
       " ('multipart(text/plain, application/x-java-applet)', 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_counter(ham_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T02:46:18.716696Z",
     "start_time": "2020-09-26T02:46:18.546745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 218),\n",
       " ('text/html', 183),\n",
       " ('multipart(text/plain, text/html)', 45),\n",
       " ('multipart(text/html)', 20),\n",
       " ('multipart(text/plain)', 19),\n",
       " ('multipart(multipart(text/html))', 5),\n",
       " ('multipart(text/plain, image/jpeg)', 3),\n",
       " ('multipart(text/html, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, application/octet-stream)', 1),\n",
       " ('multipart(text/html, text/plain)', 1),\n",
       " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that the ham mails is more textual while the spam mails has more HTML. Also, the ham mails has pgp signature and the spam does not. So, we got some info about the spam and ham emails!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T02:46:23.726591Z",
     "start_time": "2020-09-26T02:46:23.646573Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X = np.array(spam_emails + ham_emails)\n",
    "y = np.array([1] * len(spam_emails) + [0]* len(ham_emails))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T02:57:23.791260Z",
     "start_time": "2020-09-25T02:57:23.760014Z"
    }
   },
   "source": [
    "Now, we are going to either delete the HTML tags in or substitute HYPERLINK to `<a>` tags. This can be done using BeautifulSoup module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T02:46:25.886648Z",
     "start_time": "2020-09-26T02:46:25.671339Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "\n",
    "def html_to_plain_text(html):\n",
    "    soup = BeautifulSoup(html)\n",
    "    for a in soup.find_all('a'):\n",
    "        if isinstance(a, bs4.element.Tag):\n",
    "            if a.string:\n",
    "                a.string = \"HYPERLINK \" + a.string\n",
    "            else:\n",
    "                a.string = \"HYPERLINK\"\n",
    "            a.unwrap()\n",
    "    return soup.get_text()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this only works if the email is html, so we'll for now ignore all the other types of the emails. And, the plain text is already plain, we don't need to do anything!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that for multipart the text cannot be obtained. So, we are going to ignore those objects. \n",
    "we will write a function to do just that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T02:46:43.496348Z",
     "start_time": "2020-09-26T02:46:43.466507Z"
    }
   },
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        \n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "                continue\n",
    "        try:\n",
    "            content = email.get_content()\n",
    "        except:\n",
    "            content = str(email.get_payload()) #in case of encoding issues and there is a bunch        \n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "            \n",
    "    if html:\n",
    "        return html_to_plain_text(html)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T05:33:39.023250Z",
     "start_time": "2020-09-25T05:33:36.162528Z"
    }
   },
   "source": [
    "Now, we have to remove any urls that are in the text and replace them with \"URL\" in the text.\n",
    "To do that, we can use the urlextract module. Needs Internet connection for downloading root domain names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:42:03.374093Z",
     "start_time": "2020-09-26T05:42:03.293910Z"
    }
   },
   "outputs": [],
   "source": [
    "import urlextract \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "url_extractor = urlextract.URLExtract()\n",
    "try:\n",
    "    stopwords.words('english')[0:10]\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "stemmer = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:42:38.793664Z",
     "start_time": "2020-09-26T05:42:38.738690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [2, 3, 1, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemming(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "vectorizer = CountVectorizer(analyzer=stemming)\n",
    "some_vectors = vectorizer.fit_transform(some_transformed)\n",
    "some_vectors.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text  vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T07:16:27.524033Z",
     "start_time": "2020-09-26T07:16:27.492802Z"
    }
   },
   "outputs": [],
   "source": [
    "class EmailToText(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, html_convert=True):\n",
    "        self.html_convert = html_convert\n",
    "    def fit(self,X, y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            if self.html_convert:\n",
    "                text = email_to_text(email)\n",
    "                if text is None:\n",
    "                    text = \"None\"\n",
    "                X_transformed.append(text)\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T07:21:46.561380Z",
     "start_time": "2020-09-26T07:21:23.835759Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    (\"emailtotext\", EmailToText()),\n",
    "    (\"countvectorizer\", CountVectorizer(analyzer=stemming)),\n",
    "    (\"vectorizer\", TfidfTransformer())\n",
    "])\n",
    "\n",
    "X_transformed  = preprocess_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T07:26:53.049620Z",
     "start_time": "2020-09-26T07:26:52.971473Z"
    }
   },
   "outputs": [],
   "source": [
    "some = preprocess_pipeline.fit_transform(X_few)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T07:28:08.251735Z",
     "start_time": "2020-09-26T07:28:08.226960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.21409081, 0.09492157,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.05072103, ..., 0.07217686, 0.04266813,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.06020895, ..., 0.08567832, 0.05064966,\n",
       "        0.07253301],\n",
       "       [0.02942248, 0.02942248, 0.        , ..., 0.14019971, 0.08288057,\n",
       "        0.02373787],\n",
       "       [0.        , 0.        , 0.05214398, ..., 0.11130261, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some.toarray() #small example of how the sparse matrix might look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T07:23:22.915552Z",
     "start_time": "2020-09-26T07:23:22.884305Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T07:21:49.399948Z",
     "start_time": "2020-09-26T07:21:49.237168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "score = cross_val_score(sgd, X_train, y_train, cv=5, verbose=2)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T06:35:14.709007Z",
     "start_time": "2020-09-26T06:35:14.651612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 94.06% \n",
      "Recall: 80.51%\n",
      "Accuracy: 95.17%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "sgd = SGDClassifier(random_state=42)\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "print(f\"Precision: {100 * precision_score(y_test, y_pred):.2f}% \")\n",
    "print(f\"Recall: {100 * recall_score(y_test, y_pred):.2f}%\")\n",
    "print(f\"Accuracy: {(100 * accuracy_score(y_test, y_pred)):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T07:23:31.896474Z",
     "start_time": "2020-09-26T07:23:31.833971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94875"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mul_nb = MultinomialNB(alpha=0.001)\n",
    "score_nb = cross_val_score(mul_nb, X_train, y_train, cv=3)\n",
    "score_nb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T07:23:39.390324Z",
     "start_time": "2020-09-26T07:23:39.352538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 90.18% \n",
      "Recall: 85.59%\n",
      "Accuracy: 95.33%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mul_nb.fit(X_train, y_train)\n",
    "y_pred = mul_nb.predict(X_test)\n",
    "print(f\"Precision: {100 * precision_score(y_test, y_pred):.2f}% \")\n",
    "print(f\"Recall: {100 * recall_score(y_test, y_pred):.2f}%\")\n",
    "print(f\"Accuracy: {(100 * accuracy_score(y_test, y_pred)):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive bayes does not do much better than the sgdclassifier. So, let's see if the ensemble does any better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T07:23:49.404339Z",
     "start_time": "2020-09-26T07:23:45.556728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 96.67% \n",
      "Recall: 73.73%\n",
      "Accuracy: 94.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "print(f\"Precision: {100 * precision_score(y_test, y_pred):.2f}% \")\n",
    "print(f\"Recall: {100 * recall_score(y_test, y_pred):.2f}%\")\n",
    "print(f\"Accuracy: {(100 * accuracy_score(y_test, y_pred)):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T07:24:16.287604Z",
     "start_time": "2020-09-26T07:24:16.202969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 94.44% \n",
      "Recall: 86.44%\n",
      "Accuracy: 96.33%\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(alpha=0.000009,penalty='l1', random_state=42)\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "print(f\"Precision: {100 * precision_score(y_test, y_pred):.2f}% \")\n",
    "print(f\"Recall: {100 * recall_score(y_test, y_pred):.2f}%\")\n",
    "print(f\"Accuracy: {(100 * accuracy_score(y_test, y_pred)):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T06:43:54.577695Z",
     "start_time": "2020-09-26T06:43:54.546420Z"
    }
   },
   "source": [
    "Since we need the model to flag spam more, we need a high value of recall value, since it calculates the amount of total positives classified correctly. Even though, the ham mails will be frequently classified to spam, the spam will be mostly classified to be the spam. So, this can be a better model for this type of problem than above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python37864bita27682b00e234f00b4a771f6dc91344e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
